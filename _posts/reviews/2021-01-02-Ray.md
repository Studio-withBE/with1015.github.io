---
title: "Ray: A Distributed Framework for Emerging AI Applications"
author: Hyunjoon Jeong
layout: post
category: review
---
본 리뷰는 OSDI'18에 게재된 논문 "Ray: A Distributed Framework for Emerging AI Applications"를 읽고 내용을 간단히 정리하고자 쓰였습니다.  
(틀린 내용이나 잘못 이해하고 있는 부분이 있다면 지적 부탁 드리겠습니다.)  

Ray를 소개하기 전, 먼저 강화 학습(Reinforcemnet Learning)이 어떤 방식으로 이루어지는지 알아야 합니다.  
강화 학습은 비지도학습으로 label이 존재하지 않고 주변의 환경과 상호작용을 통해 문제를 해결합니다.

<center><img src="/assets/images/ray_01.jpg" width="50%" height="50%"></center>  

위 그림은 강화 학습의 Agent와 환경이 어떻게 상호작용이 되는가를 나타낸 그림입니다. Agent는 환경을 보고 action을 하는 주체로, 환경의 state를 보고 reward를 계산합니다. 이러한 reward를 이용해 지속적으로 policy를 수정해 action을 결정하게 되고 수정된 policy를 문제 상황에 적용하여 해결하게 됩니다. Ray는 이러한 강화학습을 하기 위해서 3개의 시스템이 필요하다고 주장합니다.  
수정중..

\[논문 및 그림 출처] <a href="https://dl.acm.org/doi/10.5555/3291168.3291210">Ray: A Distributed Framework for Emerging AI Applications</a>, Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, and Ion Stoica, UC Berkeley. OSDI'18. <a href="https://github.com/ray-project/ray">Github</a>
