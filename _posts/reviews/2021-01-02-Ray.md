---
title: "Ray: A Distributed Framework for Emerging AI Applications"
author: Hyunjoon Jeong
layout: post
category: review
---
본 리뷰는 OSDI'18에 게재된 논문 "Ray: A Distributed Framework for Emerging AI Applications"를 읽고 내용을 간단히 정리하고자 쓰였습니다.  
(틀린 내용이나 잘못 이해하고 있는 부분이 있다면 지적 부탁 드리겠습니다.)  

Ray를 소개하기 전, 먼저 강화 학습(Reinforcemnet Learning)이 어떤 방식으로 이루어지는지 알아야 합니다.  
강화 학습은 비지도학습으로 label이 존재하지 않고 주변의 환경과 상호작용을 통해 문제를 해결합니다.

<center><img src="/assets/images/ray_01.jpg" width="50%" height="50%"></center>  

위 그림은 강화 학습의 Agent와 환경이 어떻게 상호작용이 되는가를 나타낸 그림입니다. Agent는 환경을 보고 action을 하는 주체로, 환경의 state를 보고 reward를 계산합니다. 이러한 reward를 이용해 지속적으로 policy를 수정해 action을 결정하게 되고 수정된 policy를 문제 상황에 적용하여 해결하게 됩니다. Ray는 이러한 강화학습을 하기 위해서 시스템에 아래와 같은 3가지 요소가 필요하다고 합니다.  

1. 시뮬레이션이나 다른 물리적 환경에 의해 발생한 데이터를 통해 policy를 수정하는 "training"
2. 현재 policy에 state를 적용했을 때, agent의 action을 도출하는 "serving"
3. policy를 평가하고 여러 action 선택지를 보면서 장기적으로 어떤 결과가 나타날지 탐색하는 "simulation"

Ray는 위 3가지 요소를 언급하면서 기존의 framework들은 위 3가지 요소를 시스템에 한번에 갖추고 있지 않다고 주장합니다. 예를들어 MapReduce, Spark, Dryad 같은 경우, 이들은 모두 Bulk-synchronous parallel system으로 training에 대한 작업은 가능하지만 simulation과 serving은 불가능 하다고 합니다. Tensorflow와 MXNet도 마찬가지로 이들은 Distributed deep learning framework이기 때문에 training은 가능하지만 simulation과 serving 역시 불가능 하다고 언급되어 있습니다.  
추가적으로 Ray에서는 Trajectory라는 state와 reward의 튜플이 등장합니다. Trajectory는 기존의 policy에 현재 환경의 state를 도입한 action과 이를 simulation한 결과를 통해 만들어지며 (Ray에서는 이 과정을 Roll-out이라고 표현했습니다.), 이러한 trajectory의 집합을 통해 policy를 업데이트 합니다. 이러한 policy 업데이트를 하기 위해서는 위에서 언급한 training, serving, simulation의 과정이 모두 필요하게 됩니다. 따라서 Ray에서는 시스템이 다음과 같은 능력들이 다시 요구 된다고 합니다.

1. 초당 백만 단위의 heterogeneous task들을 milisecond 단위의 latency 내에서 처리할 수 있어야 합니다.
2. Stateless, Stateful computation을 지원하기 위한 flexible한 처리 모델이 필요합니다.
3. 계산 결과는 미리 알 수 없고, 그 결과가 나중의 계산에도 영향을 미치기 때문에 dynamic computation이 가능해야 합니다.

따라서 Ray의 목표는 위 3가지 workload와 3가지 시스템 requirements를 하나의 application에 통합하는 것입니다.  

수정중...

\[논문 및 그림 출처] <a href="https://dl.acm.org/doi/10.5555/3291168.3291210">Ray: A Distributed Framework for Emerging AI Applications</a>, Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, and Ion Stoica, UC Berkeley. OSDI'18. <a href="https://github.com/ray-project/ray">Github</a>
