---
title: "AlloX: Compute Allocation in Hybrid Clusters"
author: Hyunjoon Jeong
layout: post
category: review
---
본 리뷰는 EuroSys'20에 게재된 논문 "AlloX: Compute Allocation in Hybrid Clusters"를 읽고 내용을 간단히 정리하고자 쓰였습니다.  
(틀린 내용이나 잘못 이해하고 있는 부분이 있다면 지적 부탁 드리겠습니다.)

AlloX의 motivation은 딥러닝 프레임워크에 대한 "interchangeable resource"로부터 시작합니다.  
보통 기존의 딥러닝은 GPU에서 주로 처리가 되었으나 구글의 Tensor Processing Unit (이하 TPU) 같은 장치들이 Tensorflow의 지원을 받기 시작하면서 딥러닝 클러스터가 heterogeneous computation device로 구성되게 되었습니다. 이러한 클러스터에서 장치들은 interchangeability를 가지게 되지만 이 때문에 선택되는 configuration으로 인해 딥러닝 작업별로 processing time이나 throughput에 큰 차이를 보이게 됩니다. 이에따라 AlloX의 저자들은 다음과 같은 motivation을 추가로 제시했습니다.  

1. Application 단위에서의 interchangeable resource별 성능
2. CPU와 같은 일부 resource의 under-utilization 문제
3. 기존에 존재하는 scheduling policy의 비효율성

![title](/assets/images/allox_01.jpg){: width="80%" height="80%" .centered}

위 그림과 같이 Bi-LSTM이나 video analytics 같은 작업은 GPU와 CPU를 사용하였을 때 성능이 거의 차이가 없거나 오히려 CPU에서의 작업이 더 나은 성능을 보입니다.  

![title](/assets/images/allox_02.jpg){: width="40%" height="40%" .centered} ![title](/assets/images/allox_03.jpg){: width="50%" height="50%" .centered}

또한 위 그래프는 두번째 motivation에서 언급한 바와 같이 Azure 사용자들의 CPU utilization이 대부분 20%에 못미치는 것으로 일부 resource의 under-utilization 문제를 뒷받침 해주고 있습니다. 이러한 under-utilization 문제를 해결하기 위한 방법으로 CPU와 그 외 성능에 더 유리한 resource들을 두고 적절히 스케줄링하는 방법이 있을 것입니다. 하지만 AlloX의 저자들은 기존의 스케줄링 정책은 multi-resource에 대해서는 효율적이지 않다고 언급합니다. 모든 작업들의 processing time을 알고 있다는 전제 하에 저자들은 First-Come-First-Serve (FCFS), Equal Share (ES), Best Fit (BF), Shortest Job First (SJF), Join the Shortest Queue (JSQ)등의 스케줄링 정책을 시도해보았고, 모든 작업이 끝나는 시간을 기준으로 했을 때, optimal solution과 60%까지 차이가 나타났습니다. 특히 위 SJF 그래프의 경우, 이는 작업에 걸리는 시간을 안다는 전제로 single resource에서 가장 이상적인 스케줄링 정책이지만, multi-resource 환경에서는 오히려 optimal 하지 않다는 것을 보여줍니다.  
결론적으로 AlloX의 저자들이 목표로 하는 것은 다음과 같았습니다.

1. 각각의 딥러닝 작업에 대해 어떤 configuration을 갖고 어떤 순서로 작업을 해야 하는가?
2. fairness나 작업의 길이에 구애받지 않고 어떻게 전체 작업 완료 시간을 최소화 할 수 있는가?

위 2가지 목표를 달성하기 위해서, 저자들은 AlloX의 시스템 구조를 아래 그림과 같이 "Estimator", "Scheduler", "Placer"로 나누어 설계하게 됩니다.  

![title](/assets/images/allox_04.jpg){: width="40%" height="40%" .right}  

AlloX 스케줄러의 경우, 각 작업들에 대해 processing time을 Estimator에서 각각의 configuration에 대해 추정하게 됩니다. 이 때 사용하는 방법은 실제 작업에 3% 부분만 사전에 미리 실행시키고 이를 통해 실제 작업에 시간이 얼마나 걸리는지 추정을 하게 됩니다. 물론 이와 같은 방법은 어느 정도 오차를 동반하게 되지만, AlloX의 저자들이 40개의 작업에 대해 추정 오류를 측정한 결과, 평균적으로 8% 정도의 오차가 발생했고, 약 50% 정도의 작업들이 오차가 0에 수렴했다고 주장합니다.  
AlloX 스케줄러가 각 작업에 대해 configuration과 순서를 부여하는 방식은 Min-Cost Bipartite matching 문제를 푸는 것으로 해결합니다. 또한 Estimator에서 얻은 각 configuration에 대한 추정 processing time은 scheduler 단계에서 processing matrix 형태로 표현이 됩니다.  

![title](/assets/images/allox_05.jpg){: width="40%" height="40%" .centered}  

위 그림은 processing matrix에 대한 예시를 나타냅니다. matrix P의 행은 Job을, 열은 configuration을 의미합니다. 따라서 위 그림에 matrix P는 Job 1이 GPU에서 실행했을 때 3초, CPU에서는 4초가 걸리게 된다는 것을 의미합니다. AlloX는 그 다음으로 total job completion time을 계산하기 위해서 k-th last job이라는 개념을 사용합니다.  
오른쪽 그림에 의하면 각 작업들을 GPU에서 순서대로 실행을 하는 경우, 3초, 7초, 12초가 걸리게 되면서 total completion time은 이들의 합인 22초가 됩니다. k-th last job은 total completion time을 오로지 waiting time의 관점을 통해 계산하는 방식을 의미합니다. 각 작업은 k-th last job의 index로 실행 순서의 역순으로 계산이 됩니다. 따라서 3번째로 실행된 Job 3는 k-th last job의 관점에서는 k=1로 바뀌게 됩니다. 첫번째로 실행되었던 Job 1의 경우는 k-th last job에서는 k=3이 될 것입니다. 또한 첫번째 작업인 Job 1의 경우, Job 2와 Job 3의 waiting time에 영향을 주게 됩니다. Job 1, 2, 3의 total completion time은 3 + (3 + 4) + (3 + 4 + 5) = 22이고, 이를 k-th last job 관점으로 계산을 하게 되면, (k = 1) * 5 + (k = 2) * 4 + (k = 3) * 3 = 22로 기존의 방법과 같은 결과를 나타내게 됩니다.  
결론적으로 total completion time은 k-th last job의 k 값과 해당 k 값을 가지는 processing time의 곱의 합으로 나타낼 수 있게 됩니다.  
자, 그러면 다시 AlloX 스케줄러로 돌아와서, AlloX의 목표는 결국 total completion time을 최소화 시키는 것이 목표 입니다. (물론 interchangeable resource가 있는 경우)  
AlloX의 스케줄러는 processing matrix를 작업의 개수만큼 확장시켜서 k-th last job이 포함된 cost matrix로 만들게 됩니다.  

![title](/assets/images/allox_06.jpg){: width="40%" height="40%" .centered}  

위 그림처럼 기존에 예시를 들었던 matrix P는 작업의 개수가 3개이고, k-th last job이 만들어질 수 있는 k값이 각각 곱해져서 matrix Q와 같은 cost matrix를 만들어내게 됩니다. 각 행은 matrix P와 마찬가지로 작업을 나타내고, 열은 configuration과 k-th last job의 k값의 pair에서 나타나는 processing time이 됩니다. 이제 남은 일은 이렇게 만들어진 cost matrix에서 각 행에서 다른 행과 겹치지 않는 열을 고르고, 고른 값들의 합을 최소로 만들도록 하면 그 configuration들이 각 작업에 대한 schduling configuration이 됩니다. AlloX는 이 cost matrix의 solution을 찾기 위해서 각 작업과 configruation을 두 그룹으로 나누어 bipartite graph(이분 그래프)로 만들고 두 그룹 사이의 edge를 matrix의 element로 결정합니다. 이렇게 만들어진 그래프를 Hungarian method를 통해 해결하면 O(n^3) time complexity 안에서 solution을 발견할 수 있게 됩니다. (Hungarian method에 대한 자세한 알고리즘은 이 논문에서 나오지 않습니다. 이 알고리즘에 대한 내용은 <a href="https://gazelle-and-cs.tistory.com/29">여기</a>에 더 자세히 설명이 되어 있습니다.)  
여기까지 AlloX는 각 작업들이 시작과 동시에 도착한다는 가정 하에 스케줄링 방법을 찾았습니다. 그런데 만약 scheduling 도중에 새로운 작업이 들어오게 되면 AlloX는 어떻게 처리하게 되는 것일까요? 이 경우, AlloX는 Delay Matrix를 도입하여 해결합니다. 기존의 processing matrix에 추가적인 행을 도입하고, 새로운 작업이 도착한 시간과 각 configuration에서 가장 빨리 사용될 수 있는 time의 차이값을 추가되는 행의 값으로 사용하게 됩니다.  
그렇다면 online arrival이 이렇게 되는건 좋은데, 만약 기존의 작업들에 비해 더 configuration이 좋은 작업들이 계속 들어와서 head of line 문제가 발생하게 된다면 어떻게 될까요? AlloX의 저자들은 이러한 fairness 문제가 발생할 경우, 처음에는 Dominant Resource Fairness (DRF)를 확장시켜서 해결하려 했습니다. 이를 이해하기 위해서는 AlloX와 같은 multi-resource 환경에서 fairness를 충족하기 위한 4가지 속성을 알아야 합니다. 이는 각각 Pareto Efficiency (PE), Sharing Incentive (SI), Envy Freeness (EF) 그리고 Strategy Proofness (SP)라는 이름으로 해당 논문에서 소개하고 있습니다.

1. Pareto Efficiency: 각 작업은 다른 작업의 performance를 해치지 않고서는 자신의 performance 향상이 불가능하다.
2. Sharing Incentive: 작업이 N개 만큼 있는 경우, 각 작업은 최소한 system resource의 1/N만큼 사용하는 성능이 보장되어야 한다.
3. Envy Freeness: 각 작업은 다른 작업의 throughput 향상을 위해 resource를 주는 것을 좋아하지 않는다.
4. Strategy Proofness: 거짓말을 통해 자신의 성능을 향상시키는 것은 불가능하다. (즉, 정직해야 한다.)

DRF의 경우, single configuration에서는 위 4가지를 만족하지만, multi-configuration 환경에서는 이것이 불가능 했습니다. 따라서 처음 계획은 가장 짧은 processing time을 갖는 작업의 resource configuration을 선택하고, DRF를 이용해 interchangeability를 무시하고 resource를 할당하는 방식을 사용하려 했습니다. (이 방법이 저자들이 앞서 말한 DRF를 확장시킨 방식이라고 합니다.) 하지만 이 방법을 사용하는 경우, 가장 짧은 processing time의 작업을 고르는 행동이 PR, SI를 위배하거나 SP를 위배하게 되는 방식입니다.

논문 및 그림 출처: <a href="https://dl.acm.org/doi/abs/10.1145/3342195.3387547"> AlloX: compute allocation in hybrid clusters</a>, Tan N. Le, Xiao Sun, Mosharaf Chowdhury, and Zhenhua Liu, Eurosys'20, <a href="https://github.com/lenhattan86/allox">Github</a>
